{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e077bf73-cae2-46fa-b2e8-420ea1c341f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "\n",
    "from utils import get_shd_dataset\n",
    "\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9940d2-13e8-4bd1-93eb-ecadf57a1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coarse network structure and the time steps are dicated by the SHD dataset. \n",
    "nb_inputs  = 700\n",
    "nb_hidden  = 200\n",
    "nb_outputs = 20\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps = 100\n",
    "max_time = 1.4\n",
    "lr = 2e-4\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e37958-65aa-40a9-b1b6-9e82f7ca000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b86715-0f52-42ca-97f1-e3471f2dd08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available at: /home/jason/data/hdspikes/shd_train.h5\n",
      "Available at: /home/jason/data/hdspikes/shd_test.h5\n"
     ]
    }
   ],
   "source": [
    "# Here we load the Dataset\n",
    "cache_dir = os.path.expanduser(\"~/data\")\n",
    "cache_subdir = \"hdspikes\"\n",
    "get_shd_dataset(cache_dir, cache_subdir)\n",
    "\n",
    "train_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_train.h5'), 'r')\n",
    "test_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_test.h5'), 'r')\n",
    "\n",
    "x_train = train_file['spikes']\n",
    "y_train = train_file['labels']\n",
    "x_test = test_file['spikes']\n",
    "y_test = test_file['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aaccf9d-bcd5-44e6-b39f-abca132c6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for the plots and accuracies if it doesn't exist\n",
    "output_dir = './training_outputs'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ed58ea-501d-4eba-807b-95f3c63c366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_data_generator_from_hdf5_spikes(X, y, batch_size, nb_steps, nb_units, max_time, shuffle=True):\n",
    "    \"\"\" This generator takes a spike dataset and generates spiking network input as sparse tensors. \n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y, dtype=int)\n",
    "    number_of_batches = len(labels_)//batch_size\n",
    "    sample_index = np.arange(len(labels_))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    firing_times = X['times']\n",
    "    units_fired = X['units']\n",
    "    \n",
    "    time_bins = np.linspace(0, max_time, num=nb_steps)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            times = np.digitize(firing_times[idx], time_bins)\n",
    "            units = units_fired[idx]\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            \n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "    \n",
    "        X_batch = torch.sparse_coo_tensor(i, v, torch.Size([batch_size, nb_steps, nb_units]), dtype=torch.float, device=device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb90bbd-ebce-4142-af9c-f7cd57bf0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d8c025-800c-4a96-be97-bf2beb19cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 0.2\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "v1 = torch.empty((nb_hidden, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(v1, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f75e65a-abb9-4e8b-aa97-10102c00ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ab5b8e-cf71-4f87-8e9d-34cdfbe8786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def live_plot(loss):\n",
    "    if len(loss) == 1:\n",
    "        return\n",
    "    clear_output(wait=True)\n",
    "    ax = plt.figure(figsize=(3,2), dpi=150).gca()\n",
    "    ax.plot(range(1, len(loss) + 1), loss)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.xaxis.get_major_locator().set_params(integer=True)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e240f1-47c5-47a0-86d9-bb892124a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(loss_hist, config_index, output_dir='./training_outputs'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_hist, label='Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Loss History for Configuration {config_index}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f'loss_plot_config_{config_index}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba865e4-f18f-4dd2-9569-4b0684140f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to store the test accuracies\n",
    "accuracy_file_path = os.path.join(output_dir, 'test_accuracies.txt')\n",
    "\n",
    "# Function to append accuracies to a file\n",
    "def log_accuracy(config_index, accuracy, accuracy_file_path):\n",
    "    with open(accuracy_file_path, 'a') as file:\n",
    "        file.write(f\"Configuration {config_index}: Test Accuracy = {accuracy:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9dbfa6-ed3c-422c-8475-61cd757601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"labels_\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c0f36d-d873-48fa-95d9-44e03a6b1096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs,tau_syn):\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    alpha = float(np.exp(-time_step/tau_syn)) \n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    out = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    h1_from_input = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    for t in range(nb_steps):\n",
    "        h1 = h1_from_input[:,t] + torch.einsum(\"ab,bc->ac\", (out, v1))\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1\n",
    "        new_mem =(beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eeed8ba-6277-463e-a98a-19010f17d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, lr, batch_size, nb_hidden, reg_strength, nb_epochs=10, tau_syn=5e-3, config_index=0, lr_decay=0.95, patience=5):\n",
    "    params = [w1, w2, v1]\n",
    "    optimizer = torch.optim.Adamax(params, lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "\n",
    "    loss_hist = []\n",
    "    test_accuracy_prev = 0\n",
    "    min_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in sparse_data_generator_from_hdf5_spikes(x_data, y_data, batch_size, nb_steps, nb_inputs, max_time):\n",
    "            output, recs = run_snn(x_local.to_dense(), tau_syn)\n",
    "            _, spks = recs\n",
    "            m, _ = torch.max(output, 1)\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "\n",
    "            # Regularizer loss\n",
    "            reg_loss = reg_strength * torch.sum(spks)  # L1 loss on total number of spikes\n",
    "            reg_loss += reg_strength * torch.mean(torch.sum(torch.sum(spks, dim=0), dim=0) ** 2)  # L2 loss on spikes per neuron\n",
    "            \n",
    "            # Combine supervised loss and the regularizer\n",
    "            loss_val = loss_fn(log_p_y, y_local) + reg_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        loss_hist.append(mean_loss)\n",
    "        live_plot(loss_hist)\n",
    "\n",
    "        if config_index != 0:\n",
    "            print(\"Epoch %i: loss=%.5f\" % (e + 1, mean_loss), f\"Testing configuration: {config_index}\")\n",
    "        else:\n",
    "            print(\"Epoch %i: loss=%.5f\" % (e + 1, mean_loss))\n",
    "\n",
    "        # Learning rate decay check\n",
    "        if mean_loss < min_loss:\n",
    "            min_loss = mean_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            lr *= lr_decay\n",
    "            epochs_no_improve = 0\n",
    "            print(f\"Reduced learning rate to {lr:.6f} due to no improvement in loss\")\n",
    "\n",
    "        # Test accuracy check\n",
    "        if e % 7 == 0:\n",
    "            test_accuracy = compute_classification_accuracy(x_test, y_test, tau_syn=tau_syn)\n",
    "            if test_accuracy_prev <= test_accuracy:\n",
    "                test_accuracy_prev = test_accuracy\n",
    "            else:\n",
    "                print(\"No improvement in test accuracy, stopping early.\")\n",
    "                break\n",
    "        \n",
    "    return loss_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7741a9f-3cc6-4d3d-b4d5-d1ca4f859393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initWeights():\n",
    "    global w1, w2, v1\n",
    "    # Reinitialize weights here to ensure they're reset for every new run\n",
    "    w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "    torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "    \n",
    "    w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "    torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "    v1 = torch.empty((nb_hidden, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
    "    torch.nn.init.normal_(v1, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f29f7bc4-c453-4e3a-b8f1-98960661850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(x_data, y_data,tau_syn):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    for x_local, y_local in sparse_data_generator_from_hdf5_spikes(x_data, y_data, batch_size, nb_steps, nb_inputs, max_time, shuffle=False):\n",
    "        output, other_recordings = run_snn(x_local.to_dense(), tau_syn)\n",
    "        m,_= torch.max(output,1) # max over time\n",
    "        _,am=torch.max(m,1)      # argmax over output units\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54ed4a65-2119-411d-a028-a8a0765a51cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations generated: 45\n",
      "{'nb_hidden': 100, 'reg_strength': 0, 'tau_syn': 0.001}\n",
      "{'nb_hidden': 100, 'reg_strength': 0, 'tau_syn': 0.005}\n",
      "{'nb_hidden': 100, 'reg_strength': 0, 'tau_syn': 0.01}\n",
      "{'nb_hidden': 100, 'reg_strength': 1e-06, 'tau_syn': 0.001}\n",
      "{'nb_hidden': 100, 'reg_strength': 1e-06, 'tau_syn': 0.005}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "param_space = {\n",
    "    'nb_hidden': [100, 200, 300],\n",
    "    'reg_strength': [0, 1e-6, 1e-5, 1e-4, 1e-3],\n",
    "    'tau_syn': [1e-3, 5e-3, 10e-3]  # Added different values for synaptic time constant\n",
    "}\n",
    "\n",
    "# param_space = {\n",
    "#     'lr': [1e-5, 1e-4],\n",
    "#     'nb_hidden': [100],\n",
    "#     'reg_strength': [0],\n",
    "# }\n",
    "\n",
    "# Generate all possible combinations\n",
    "all_combinations = list(itertools.product(\n",
    "    param_space['nb_hidden'],\n",
    "    param_space['reg_strength'],\n",
    "    param_space['tau_syn']  # Include in the product\n",
    "))\n",
    "\n",
    "# Converting tuples from product to dictionaries\n",
    "configs = [\n",
    "    {'nb_hidden': nb_hidden, 'reg_strength': reg_strength, 'tau_syn': tau_syn}\n",
    "    for nb_hidden, reg_strength, tau_syn in all_combinations\n",
    "]\n",
    "\n",
    "# Verify the length of configs and print the first few to check\n",
    "print(\"Total configurations generated:\", len(configs))\n",
    "for config in configs[:5]:\n",
    "    print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da789c46-0bb1-44c9-91a5-994b6582f4e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: loss=1.38285 Testing configuration: 1\n"
     ]
    }
   ],
   "source": [
    "# Test different hyperparameter configurations to max 200 epochs each\n",
    "nb_epochs = 200\n",
    "best_test_accuracy = 0\n",
    "best_config = configs[0]\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"Testing configuration {i+1} of {len(configs)}\")\n",
    "    loss_hist = train(x_train, y_train, lr=lr, batch_size=256, nb_hidden=config['nb_hidden'], reg_strength=config['reg_strength'], tau_syn = config['tau_syn'], config_index=i+1, nb_epochs=nb_epochs)\n",
    "    test_accuracy = compute_classification_accuracy(x_test, y_test,tau_syn = config['tau_syn'])\n",
    "    print(f\"Test accuracy for configuration {i+1}: {test_accuracy:.3f}\")\n",
    "    # Log accuracy to file and save the loss plot\n",
    "    log_accuracy(i+1, test_accuracy, accuracy_file_path)\n",
    "    save_plot(loss_hist, i+1)\n",
    "    \n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        print(\"New best!\")\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_config = config\n",
    "initWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc87bb-f101-4041-946c-27e2b8c90918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model on 200 epochs (Or until test accuracy gets worse)\n",
    "initWeights()\n",
    "nb_epochs = 200\n",
    "loss_hist = train(x_train, y_train, lr=lr, batch_size=256, nb_hidden=best_config['nb_hidden'], reg_strength=best_config['reg_strength'], tau_syn = best_config['tau_syn'], config_index=0, nb_epochs=nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf4740-a1b1-47ec-8627-2b6691b00a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best hyperparameter config:{best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2cf6cc-5fc9-4e54-a631-d9545fa682a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(x_train,y_train,tau_syn = best_config['tau_syn'])))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(x_test,y_test,tau_syn = best_config['tau_syn'])))\n",
    "print(f\"Best hyperparameter config:{best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4333efc-046a-4f0f-8dbd-8aa40e35c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mini_batch(x_data, y_data, shuffle=False):\n",
    "    for ret in sparse_data_generator_from_hdf5_spikes(x_data, y_data, batch_size, nb_steps, nb_inputs, max_time, shuffle=shuffle):\n",
    "        return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decd78d-da90-4fc9-a4b7-a6cc55d0a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = get_mini_batch(x_test, y_test)\n",
    "output, other_recordings = run_snn(x_local.to_dense(), tau_syn = best_config['tau_syn'])\n",
    "mem_rec, spk_rec = other_recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91632d1-0b9e-4c19-901c-59ca8dc1c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=100)\n",
    "plot_voltage_traces(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013985a8-6344-47d0-9909-2c58614bd33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the hiddden layer spiking activity for some input stimuli\n",
    "\n",
    "nb_plt = 4\n",
    "gs = GridSpec(1,nb_plt)\n",
    "fig= plt.figure(figsize=(7,3),dpi=150)\n",
    "for i in range(nb_plt):\n",
    "    plt.subplot(gs[i])\n",
    "    plt.imshow(spk_rec[i].detach().cpu().numpy().T,cmap=plt.cm.gray_r, origin=\"lower\" )\n",
    "    if i==0:\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Units\")\n",
    "\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19511c5-4f17-4809-9aee-73838900a1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
